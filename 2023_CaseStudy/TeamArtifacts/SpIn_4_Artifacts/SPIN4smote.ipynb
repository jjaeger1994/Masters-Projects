{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balancing Notebook\n",
    "\n",
    "### Our target variables are quite imbalanced in our dataset. This notebook uses Synthetic Minority Over-sampling Technique (SMOTE) to create new synthetic samples that are similar to existing observations in the minority class. By creating a dataset with balanced target variables we hope to improve model performance and in particular increase the predictive ability on the minority class (experienced fracture). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. [Installation and Importing of Libraries](#eda_import)\n",
    "#### 2. [SMOTE](#eda_smote)\n",
    "#### 3. [Write a CSV of cleaned data](#eda_csv) (TO-DO: dependent on outcome variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"eda_import\"></a>Installation and Importing of Libraries\n",
    "In order to both explore and visualize the data, it's necessary for us to load various libraries. The first cell installs packages necessary for imblearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cmake in /opt/conda/lib/python3.7/site-packages (3.26.4)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (1.0.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn) (1.3.1)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn) (1.7.3)\n",
      "Requirement already satisfied: numpy>=1.14.6 in /opt/conda/lib/python3.7/site-packages (from scikit-learn) (1.17.3)\n",
      "Requirement already satisfied: imblearn in /opt/conda/lib/python3.7/site-packages (0.0)\n",
      "Requirement already satisfied: imbalanced-learn in /opt/conda/lib/python3.7/site-packages (from imblearn) (0.10.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.7/site-packages (from imbalanced-learn->imblearn) (1.17.3)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /opt/conda/lib/python3.7/site-packages (from imbalanced-learn->imblearn) (1.0.2)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.7/site-packages (from imbalanced-learn->imblearn) (1.7.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from imbalanced-learn->imblearn) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from imbalanced-learn->imblearn) (1.3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install cmake\n",
    "\n",
    "!pip install scikit-learn\n",
    "\n",
    "!pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##import libraries required for analysis\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"eda_smote\"></a>SMOTE\n",
    "\n",
    "Below is the code to retrieve the clean csv from our merged_data folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set file path\n",
    "file_path = \"/dsa/groups/casestudy2023su/team03/merged_data/mros_merged_clean.csv\"\n",
    "\n",
    "# Load dataframe from CSV\n",
    "merged_df = pd.read_csv(file_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B1TRD</th>\n",
       "      <th>B1ITD</th>\n",
       "      <th>B1FND</th>\n",
       "      <th>B1L1D</th>\n",
       "      <th>B1L3D</th>\n",
       "      <th>B1TBD</th>\n",
       "      <th>B1HDD</th>\n",
       "      <th>B1LAD</th>\n",
       "      <th>B1RAD</th>\n",
       "      <th>B1LRD</th>\n",
       "      <th>...</th>\n",
       "      <th>RADIALPULSE_MEAS1</th>\n",
       "      <th>BMI</th>\n",
       "      <th>HEIGHTCHANGEFROM25</th>\n",
       "      <th>WEIGHTCHANGEFROM25</th>\n",
       "      <th>FAFXN</th>\n",
       "      <th>FAFXNT</th>\n",
       "      <th>GIAGE1</th>\n",
       "      <th>FAFXN_BIN</th>\n",
       "      <th>FAFXNT_BIN</th>\n",
       "      <th>outlier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5994.000000</td>\n",
       "      <td>5994.000000</td>\n",
       "      <td>5994.000000</td>\n",
       "      <td>5994.000000</td>\n",
       "      <td>5994.000000</td>\n",
       "      <td>5994.000000</td>\n",
       "      <td>5994.000000</td>\n",
       "      <td>5994.000000</td>\n",
       "      <td>5994.000000</td>\n",
       "      <td>5994.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5994.000000</td>\n",
       "      <td>5994.000000</td>\n",
       "      <td>5994.000000</td>\n",
       "      <td>5994.000000</td>\n",
       "      <td>5994.000000</td>\n",
       "      <td>5994.000000</td>\n",
       "      <td>5994.000000</td>\n",
       "      <td>5994.000000</td>\n",
       "      <td>5994.000000</td>\n",
       "      <td>5994.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.764990</td>\n",
       "      <td>1.111712</td>\n",
       "      <td>0.784170</td>\n",
       "      <td>0.979764</td>\n",
       "      <td>1.098752</td>\n",
       "      <td>1.167219</td>\n",
       "      <td>2.132447</td>\n",
       "      <td>0.848691</td>\n",
       "      <td>0.861511</td>\n",
       "      <td>0.706571</td>\n",
       "      <td>...</td>\n",
       "      <td>64.349891</td>\n",
       "      <td>27.378324</td>\n",
       "      <td>3.705292</td>\n",
       "      <td>10.339891</td>\n",
       "      <td>0.432432</td>\n",
       "      <td>0.343577</td>\n",
       "      <td>73.657658</td>\n",
       "      <td>0.253420</td>\n",
       "      <td>0.214715</td>\n",
       "      <td>0.899900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.127367</td>\n",
       "      <td>0.166538</td>\n",
       "      <td>0.128116</td>\n",
       "      <td>0.176903</td>\n",
       "      <td>0.207320</td>\n",
       "      <td>0.126578</td>\n",
       "      <td>0.332499</td>\n",
       "      <td>0.091894</td>\n",
       "      <td>0.092162</td>\n",
       "      <td>0.135757</td>\n",
       "      <td>...</td>\n",
       "      <td>9.989382</td>\n",
       "      <td>3.829940</td>\n",
       "      <td>2.960090</td>\n",
       "      <td>11.375341</td>\n",
       "      <td>1.002012</td>\n",
       "      <td>0.813297</td>\n",
       "      <td>5.872264</td>\n",
       "      <td>0.435006</td>\n",
       "      <td>0.410659</td>\n",
       "      <td>0.436133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.167047</td>\n",
       "      <td>0.389357</td>\n",
       "      <td>0.272729</td>\n",
       "      <td>0.298691</td>\n",
       "      <td>0.382238</td>\n",
       "      <td>0.764788</td>\n",
       "      <td>1.056920</td>\n",
       "      <td>0.515547</td>\n",
       "      <td>0.515601</td>\n",
       "      <td>0.443625</td>\n",
       "      <td>...</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>17.211000</td>\n",
       "      <td>-30.180000</td>\n",
       "      <td>-42.393700</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.677239</td>\n",
       "      <td>0.998989</td>\n",
       "      <td>0.696196</td>\n",
       "      <td>0.859821</td>\n",
       "      <td>0.955975</td>\n",
       "      <td>1.083122</td>\n",
       "      <td>1.905628</td>\n",
       "      <td>0.791598</td>\n",
       "      <td>0.804045</td>\n",
       "      <td>0.636937</td>\n",
       "      <td>...</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>24.777850</td>\n",
       "      <td>1.970000</td>\n",
       "      <td>2.994512</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.758539</td>\n",
       "      <td>1.104805</td>\n",
       "      <td>0.773544</td>\n",
       "      <td>0.968030</td>\n",
       "      <td>1.081870</td>\n",
       "      <td>1.157550</td>\n",
       "      <td>2.113950</td>\n",
       "      <td>0.843987</td>\n",
       "      <td>0.856622</td>\n",
       "      <td>0.691454</td>\n",
       "      <td>...</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>26.905750</td>\n",
       "      <td>3.590000</td>\n",
       "      <td>9.365350</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.847302</td>\n",
       "      <td>1.221518</td>\n",
       "      <td>0.860129</td>\n",
       "      <td>1.086195</td>\n",
       "      <td>1.219765</td>\n",
       "      <td>1.241125</td>\n",
       "      <td>2.339317</td>\n",
       "      <td>0.898742</td>\n",
       "      <td>0.913262</td>\n",
       "      <td>0.751444</td>\n",
       "      <td>...</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>29.490625</td>\n",
       "      <td>5.240000</td>\n",
       "      <td>17.125600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.699030</td>\n",
       "      <td>1.984450</td>\n",
       "      <td>1.598350</td>\n",
       "      <td>1.976850</td>\n",
       "      <td>2.245680</td>\n",
       "      <td>2.046580</td>\n",
       "      <td>4.695200</td>\n",
       "      <td>1.945820</td>\n",
       "      <td>2.139360</td>\n",
       "      <td>4.667740</td>\n",
       "      <td>...</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>50.668700</td>\n",
       "      <td>30.870000</td>\n",
       "      <td>69.257700</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 269 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             B1TRD        B1ITD        B1FND        B1L1D        B1L3D  \\\n",
       "count  5994.000000  5994.000000  5994.000000  5994.000000  5994.000000   \n",
       "mean      0.764990     1.111712     0.784170     0.979764     1.098752   \n",
       "std       0.127367     0.166538     0.128116     0.176903     0.207320   \n",
       "min       0.167047     0.389357     0.272729     0.298691     0.382238   \n",
       "25%       0.677239     0.998989     0.696196     0.859821     0.955975   \n",
       "50%       0.758539     1.104805     0.773544     0.968030     1.081870   \n",
       "75%       0.847302     1.221518     0.860129     1.086195     1.219765   \n",
       "max       1.699030     1.984450     1.598350     1.976850     2.245680   \n",
       "\n",
       "             B1TBD        B1HDD        B1LAD        B1RAD        B1LRD  ...  \\\n",
       "count  5994.000000  5994.000000  5994.000000  5994.000000  5994.000000  ...   \n",
       "mean      1.167219     2.132447     0.848691     0.861511     0.706571  ...   \n",
       "std       0.126578     0.332499     0.091894     0.092162     0.135757  ...   \n",
       "min       0.764788     1.056920     0.515547     0.515601     0.443625  ...   \n",
       "25%       1.083122     1.905628     0.791598     0.804045     0.636937  ...   \n",
       "50%       1.157550     2.113950     0.843987     0.856622     0.691454  ...   \n",
       "75%       1.241125     2.339317     0.898742     0.913262     0.751444  ...   \n",
       "max       2.046580     4.695200     1.945820     2.139360     4.667740  ...   \n",
       "\n",
       "       RADIALPULSE_MEAS1          BMI  HEIGHTCHANGEFROM25  WEIGHTCHANGEFROM25  \\\n",
       "count        5994.000000  5994.000000         5994.000000         5994.000000   \n",
       "mean           64.349891    27.378324            3.705292           10.339891   \n",
       "std             9.989382     3.829940            2.960090           11.375341   \n",
       "min            36.000000    17.211000          -30.180000          -42.393700   \n",
       "25%            58.000000    24.777850            1.970000            2.994512   \n",
       "50%            64.000000    26.905750            3.590000            9.365350   \n",
       "75%            70.000000    29.490625            5.240000           17.125600   \n",
       "max           198.000000    50.668700           30.870000           69.257700   \n",
       "\n",
       "             FAFXN       FAFXNT       GIAGE1    FAFXN_BIN   FAFXNT_BIN  \\\n",
       "count  5994.000000  5994.000000  5994.000000  5994.000000  5994.000000   \n",
       "mean      0.432432     0.343577    73.657658     0.253420     0.214715   \n",
       "std       1.002012     0.813297     5.872264     0.435006     0.410659   \n",
       "min       0.000000     0.000000    64.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000    69.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000    73.000000     0.000000     0.000000   \n",
       "75%       1.000000     0.000000    78.000000     1.000000     0.000000   \n",
       "max      12.000000    12.000000   100.000000     1.000000     1.000000   \n",
       "\n",
       "           outlier  \n",
       "count  5994.000000  \n",
       "mean      0.899900  \n",
       "std       0.436133  \n",
       "min      -1.000000  \n",
       "25%       1.000000  \n",
       "50%       1.000000  \n",
       "75%       1.000000  \n",
       "max       1.000000  \n",
       "\n",
       "[8 rows x 269 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into X and y by dropping target variables from our X variables and using one target at a time for y variable. Also used get_dummies to transform some categorical features.\n",
    "X = pd.get_dummies(merged_df.drop(['FAFXN', 'FAFXNT', 'FAFXN_BIN', 'FAFXNT_BIN'], axis=1)) \n",
    "y = merged_df['FAFXNT_BIN'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    4707\n",
      "1    1287\n",
      "Name: FAFXNT_BIN, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Display the count of each class in the target prior to rebalancing\n",
    "print(y.value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It is important to split the data into train, test prior to resampling to avoid leakage from the test and validation sets into the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating initial temp split of 10% for testing\n",
    "\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "#second split of 10% for validation... leaving us with 80% for training.\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.1111, random_state=42) # 0.1111 * 0.9 = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    3748\n",
      "0    3748\n",
      "Name: FAFXNT_BIN, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#fit smote and create new X and y resampled\n",
    "sm = SMOTE(random_state=42)\n",
    "X_res, y_res = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "print(y_res.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a simple logistic regression model to evaluate performance between training data before and after resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for resampled training data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.15      0.26       471\n",
      "           1       0.23      0.95      0.38       129\n",
      "\n",
      "    accuracy                           0.32       600\n",
      "   macro avg       0.57      0.55      0.32       600\n",
      "weighted avg       0.77      0.32      0.29       600\n",
      "\n",
      "Classification report for original training data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.95      0.87       471\n",
      "           1       0.38      0.12      0.18       129\n",
      "\n",
      "    accuracy                           0.77       600\n",
      "   macro avg       0.59      0.53      0.52       600\n",
      "weighted avg       0.71      0.77      0.72       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Scaling data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_res_scaled = scaler.fit_transform(X_res)\n",
    "\n",
    "# logistic regression model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Fit resampled and scaled training data\n",
    "model.fit(X_res_scaled, y_res)\n",
    "\n",
    "# predictions on the test\n",
    "y_test_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# evaluate model performance\n",
    "print(\"Classification report for resampled training data:\")\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "# Fit original and scaled training data\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# predictions on the test set\n",
    "y_test_pred_orig = model.predict(X_test_scaled)\n",
    "\n",
    "# evaluate model performance\n",
    "print(\"Classification report for original training data:\")\n",
    "print(classification_report(y_test, y_test_pred_orig))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
