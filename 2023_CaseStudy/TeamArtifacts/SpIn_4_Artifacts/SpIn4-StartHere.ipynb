{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SpIn 4 - StartHere -- Notebook workflow/pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook indexes the workflow/pipeline for SpIn #4\n",
    "\n",
    "These two weeks we made significant progress.  We focused on additonal tweaks to our form data so that we could merge the data back together with our target variables.  This allowed us to begin exploring various modeling opportunities. \n",
    "\n",
    "### Data Merging and Carpentry\n",
    "These notebooks merge the data into a final data set for use in our predictive modeling. \n",
    "1. [Data3.ipynb](Data3.ipynb)\n",
    "    1. Create a merged dataset from all of the EDA files\n",
    "    1. Perform Numeric Conversion of merged dataset\n",
    "    1. Create binary variables for our target variables\n",
    "    1. Split the data into training and test data\n",
    "    1. Export for analysis into a shared folder\n",
    "\n",
    "\n",
    "    \n",
    "### Exploratory Data Analysis \n",
    "This spin, all group members amended their EDAs from SpIn #3 to create a final cleaned dataset which included null values for use with modeling and non-null values. The replacement of null values was achieved through various methods (K nearest neighbors, 0, mode) depending on the nature of the questions. Additionally, an analysis of the target variables was done. \n",
    "\n",
    "1. [Bone Mineral Density](EDA4-B1.ipynb)\n",
    "1. [Dietary Health - DH](EDA4-V1-DH.ipynb)\n",
    "1. [Functional Vision - FV](EDA4-V1-FV.ipynb)\n",
    "1. [Grip Strength - GS](EDA4-V1-GS.ipynb)\n",
    "1. [Height and Weight - HW](EDA4-V1-HW.ipynb)\n",
    "1. [Nottingham Power Rig - NP](EDA4-V1-NP.ipynb)\n",
    "1. [Medical History - MH](EDA4-V1-MH.ipynb)\n",
    "1. [Medication Use - MU](EDA4-V1-MU.ipynb)\n",
    "1. [Neruomuscular Function - NF](EDA4-V1-NF.ipynb)\n",
    "1. [Tabacco & Alcohol Use - TU](EDA4-V1-TU.ipynb)\n",
    "1. [Fracture History - FF](EDA4-V1-FF.ipynb)\n",
    "1. [General Information - GI](EDA4-V1-GI.ipynb)\n",
    "1. [Fracture Outcomes Analysis](EDA4_Fracture.ipynb) \n",
    "\n",
    "#### Feature Reduction Analysis\n",
    "We've been continuing to look at different methods of Feature Reduction in addition to what's done in our [SPIN4cleanup.ipynb](SPIN4cleanup.ipynb).  This notebook is an example of using SMOTE with Boruta.  \n",
    "1. [SMOTE + Boruta](SPIN4_SMOTE_Boruta.ipynb)\n",
    "    1. Numeric Conversion of merged dataset\n",
    "    1. Handling of NAs with KNN\n",
    "    1. Feature Reduction\n",
    "    1. Outlier Detection\n",
    "1. [EDA4_Feature_Reduction_and_Outliers.ipynb](EDA4_Feature_Reduction_and_Outliers.ipynb)\n",
    "    1. Analysis of correlated variables\n",
    "    1. Analysis of outliers using multivariate techniques\n",
    "\n",
    "\n",
    "### Modeling\n",
    "As Dr. Green remarked, we've started to get to the fun stuff! Each team member is utilizing a different model to examine feature importance as well as predictive capabilities on the test set. We currently have attempts at modeling with random forest, lightGBM, and XGBoost. Our plan for the coming week will be to discuss what features each of us found important and then start tuning the hyperparemeters for these models accordingly. \n",
    "1. [Random forest](MODEL4_Random_Forest.ipynb)\n",
    "1. [Light GBM](EDA4_Feature_Exploration_with_LightGBM.ipynb)\n",
    "1. [XGBoost](EDA4_XGBoost_POC.ipynb)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
